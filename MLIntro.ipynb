{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2019 [Sebastian Raschka](sebastianraschka.com)\n",
    "\n",
    "https://github.com/rasbt/python-machine-learning-book-3rd-edition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1 - Giving Computers the Ability to Learn from Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Building intelligent machines to transform data into knowledge](#Building-intelligent-machines-to-transform-data-into-knowledge)\n",
    "- [The three different types of machine learning](#The-three-different-types-of-machine-learning)\n",
    "    - [Making predictions about the future with supervised learning](#Making-predictions-about-the-future-with-supervised-learning)\n",
    "        - [Classification for predicting class labels](#Classification-for-predicting-class-labels)\n",
    "        - [Regression for predicting continuous outcomes](#Regression-for-predicting-continuous-outcomes)\n",
    "    - [Solving interactive problems with reinforcement learning](#Solving-interactive-problems-with-reinforcement-learning)\n",
    "    - [Discovering hidden structures with unsupervised learning](#Discovering-hidden-structures-with-unsupervised-learning)\n",
    "        - [Finding subgroups with clustering](#Finding-subgroups-with-clustering)\n",
    "        - [Dimensionality reduction for data compression](#Dimensionality-reduction-for-data-compression)\n",
    "        - [An introduction to the basic terminology and notations](#An-introduction-to-the-basic-terminology-and-notations)\n",
    "- [A roadmap for building machine learning systems](#A-roadmap-for-building-machine-learning-systems)\n",
    "    - [Preprocessing - getting data into shape](#Preprocessing--getting-data-into-shape)\n",
    "    - [Training and selecting a predictive model](#Training-and-selecting-a-predictive-model)\n",
    "    - [Evaluating models and predicting unseen data instances](#Evaluating-models-and-predicting-unseen-data-instances)\n",
    "- [Using Python for machine learning](#Using-Python-for-machine-learning)\n",
    "- [Installing Python packages](#Installing-Python-packages)\n",
    "- [Summary](#Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning (ML)\n",
    "\n",
    "- a subfield of Artificial Integlligence (AI)\n",
    "- application and science of algorithms that make sense of data\n",
    "- one of the most exciting fields in the CS!\n",
    "- with abundant of data (~ 2MB data created per second per person!), ML algorithms can be used to spot patterns in data and make predictios about the future events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building intelligent machines/algorithms to transform data into knowledge\n",
    "\n",
    "- data is abundant in both structured and unstructed form\n",
    "- ML involves self-learning algorithms that derive knowledge from data in order to make predictions\n",
    "- ML applications are already ubiquitous:\n",
    "    - spam filter\n",
    "    - web search engines\n",
    "    - Network intrusion detection and prevention system\n",
    "    - digital assistants (Apple Siri, Amazon Alexa, Google Assistant, Microsoft Cortana, etc.)\n",
    "    - self-driving cars (Google, Uber, Tesla, etc.)\n",
    "    - skin cancer detection (https://www.nature.com/articles/nature21056)\n",
    "    - AlphaZero from DeepMind has beaten human champions in Chess, Go and Shogi (Japanese Chess)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three different types of machine learning\n",
    "\n",
    "![ML Types](./images/01_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning\n",
    "\n",
    "- goal is to learn a model from labeled training data that allows us to make predictions about unseen/unlabeled data\n",
    "\n",
    "![supervised learning](./images/01_02.png)\n",
    "\n",
    "- two types: **classification** and **regression**\n",
    "\n",
    "### Classification\n",
    "\n",
    "- classify samples/data to fixed discreted class (labels)\n",
    "- can be binary class classification\n",
    "    - e.g. labeling emails as spam or ham, classify internet traffic as malicious or benign, classify programs as malware or benign, classify tumor or benign, etc.\n",
    "- can bee multi-class classification\n",
    "    - classify type of malware (adware, spyware, trojans, keyloggers, rootkits, etc.)\n",
    "    - classify type various stages of cancer (stage 0-4)\n",
    "    - classify images of people, etc.\n",
    "- the following figure depicts binary classification problem between **+** and **-** samples    \n",
    "![Binary Classification](./images/01_03.png)\n",
    "\n",
    "### Regression\n",
    "\n",
    "- the outcome is continous value\n",
    "    - e.g. predicting stock prices, home prices, weather prediction (max/min temps, wind speed, humidity), etc.\n",
    "- the following figure depicts predicting continuous outcomes given some data\n",
    "- given a feature variable, $x$, and a targe variable $y$, we fit a straight line to this data that minimizes the distance between the data points and the fitted line\n",
    "\n",
    "![Continous Outcomes](./images/01_04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning\n",
    "\n",
    "- goal is to develop a system (agent) that improves its performance based on interactions with the environment\n",
    "    - loosely speaking, this is AI\n",
    "    - similar to how humans and animals with intelligence learn\n",
    "\n",
    "- the heart of the system is so-called **reward signal**\n",
    "    - reward can be positive (good) or negative (bad)\n",
    "    - e.g. training dogs by giving rewards\n",
    "- the agent interacts with the environment and learn a series of actions by maximizing the rewards via trial-and-error or planning\n",
    "- the following figure depicts reinforcement learning\n",
    "\n",
    "![Reinforcement Learning](./images/01_05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning\n",
    "\n",
    "- deal with unlabelled data or data of unknown structure\n",
    "- technique can be used to extract meaningful information without the guidance of a known outcome variable or reward function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding subgroups with clustering\n",
    "\n",
    "- finding natural or meaningful subgroups (**clusters**) without having any prior knowledge\n",
    "- the following figure illustrates clustering of data into 3 sub-groups\n",
    "\n",
    "![Clustering](./images/01_06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic terminology and notations\n",
    "\n",
    "### Dataset and representation\n",
    "\n",
    "- most ML algorithms learn from data\n",
    "- classic example of machine learning dataset is the Iris dataset\n",
    "- contains the measurements of 150 Iris flowers from three species: Setosa, Versicolor and Virginica\n",
    "- the measuresments are also called the features\n",
    "- dataset is typically 2-dimensional matrix\n",
    "- each row represents a sample/observation/instance and each column is a feature value for that sample\n",
    "- the following figure represents a slice of the Iris dataset\n",
    "\n",
    "\n",
    "### Irisi Dataset\n",
    "\n",
    "![Iris Setosa](../images/iris_flowers.jpeg)\n",
    "\n",
    "![Iris Dataset](./images/01_08.png)\n",
    "\n",
    "\n",
    "- Iris dataset with 150 samples and four features can be written as a $150x4$ matrix:\n",
    "\n",
    "    $\n",
    "    \\begin{equation*}\n",
    "    \\textbf{X} \\in {\\mathbb{R}}^{150x4} : \\textbf{X}^{150x4} =\n",
    "    \\begin{bmatrix}\n",
    "    x_{1}^{1} & x_2^{1} & x_3^{1} & x_4^{1} \\\\\n",
    "    x_{1}^{2} & x_2^{2} & x_3^{2} & x_4^{2} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "    x_{1}^{150} & x_2^{150} & x_3^{150} & x_4^{150}\n",
    "    \\end{bmatrix}\n",
    "    \\end{equation*}\n",
    "    $\n",
    "\n",
    "\n",
    "\n",
    "### Notational Conventions\n",
    "- List of Mathematical Symbols: https://oeis.org/wiki/List_of_LaTeX_mathematical_symbols\n",
    "- superscript $i$ refers to the $i^{th}$ sample/example\n",
    "- subscript $j$ refers to the $j^{th}$ dimension/feature of the sample\n",
    "- lowercase, bold-face letters refer to a single vector $\\textbf{x} \\in \\mathbb{R}^{1xm}$\n",
    "- uppercase, bold-face letters refer to a matrix $\\textbf{X} \\in \\mathbb{R}^{nxm}$\n",
    "- single element in a vector represented in italics: $\\textit{x}_{m}$\n",
    "- single element in a matrix represented in italics: $\\textit{x}_m^{(n)}$\n",
    "\n",
    "### E.g.\n",
    "- $x_1^{(150)}$ refers to the first dimension of flower sample #150 **(sepal length)**\n",
    "- $i^{th}$ flower sample in the matrix can be written as a 4-dimensional row vector:\n",
    "\n",
    "    $ \\textbf{x}^{(i)} \\in \\mathbb{R}^{1x4}: \\textbf{x}^{(i)} = \\begin{bmatrix} x_1^{(i)} & x_2^{(i)} & x_3^{(i)} & x_4^{(i)}\\end{bmatrix}$\n",
    "    \n",
    "- $j^{th}$ feature in matrix is a 150-dimensional column vector:\n",
    "\n",
    "    $\\begin{equation*}\n",
    "    \\textbf{x}_{j} \\in \\mathbb{R}^{150x1}: \\textbf{x}_{j} = \n",
    "    \\begin{bmatrix} \n",
    "       x_j^{(1)} \\\\\n",
    "       x_j^{(2)} \\\\\n",
    "       \\vdots\\\\\n",
    "       x_j^{(150)}\n",
    "    \\end{bmatrix}\n",
    "    \\end{equation*}\n",
    "    $\n",
    "    \n",
    "- target variables is 150-dimensional column vector:\n",
    "\n",
    "$\\textbf{y} = \\begin{bmatrix} \n",
    "    y^{(1)} \\\\\n",
    "    y^{(2)} \\\\\n",
    "    \\vdots \\\\\n",
    "    y^{(150)}\n",
    "    \\end{bmatrix}\n",
    "    (y \\in \\{Setosa, Versicolor, Virginica\\})\n",
    "$\n",
    "\n",
    "### Training sample\n",
    "- a row in a table representating the dataset also called observation, record, instance\n",
    "\n",
    "### Training\n",
    "- Model fitting, similar to parameter estimation\n",
    "\n",
    "### Feature\n",
    "- a column in a data table (matrix), also called variable, attribute or covariate, input\n",
    "\n",
    "### Target\n",
    "- also called outcome, class, label, response variable, ground truth, dependent variable\n",
    "\n",
    "### Loss function\n",
    "- also called cost function, error function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Public Repository of Machine Learning Datasets\n",
    "\n",
    "1. UCI Machine Learning Repository - https://archive.ics.uci.edu/ml/datasets.php\n",
    "2. UNB - Canadian Institute for Cybersecurity Datasets - https://www.unb.ca/cic/datasets/index.html\n",
    "3. Kaggle Public Datasets - https://www.kaggle.com/datasets\n",
    "4. Sci-kit learn Real-World Datasets -  https://scikit-learn.org/stable/datasets/real_world.html\n",
    "5. Seaborn Datasets - https://github.com/mwaskom/seaborn-data\n",
    "6. https://www.openml.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A roadmap for building machine learning systems\n",
    "\n",
    "- the following figure shows a typical workflow for using machine learning in predictive modeling\n",
    "\n",
    "![Overview of ML systems](./images/01_09.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing - getting data into shape\n",
    "\n",
    "- raw data can be structured (csv, xml, json, database, etc.) or unstructured (text, images, videos, audios, etc.)\n",
    "- it's important to convert raw data into feature vector by extracting appropriate features\n",
    "    - e.g. in Iris dataset, sepal and petal length and width\n",
    "- feature values are preferred to be on the same scale for optimal performance typically in the range [0, 1]\n",
    "    - standard normal distribution with zero mean and unit variance (covered in later chapters)\n",
    "- features may be highly correlated and therefore redundant to a certain degree\n",
    "    - feature selection and dimensionality reduction techniques are used\n",
    "    - requires less memory and CPU time\n",
    "    - may improve predictive performance of model\n",
    "    - reduce noise (remove irrelevant features)\n",
    "- dataset is typically divided into two parts (training set and testing/validation set)\n",
    "- **training set** is used to train the model\n",
    "- **testing/validation set** is used to evaulate the model to see how it would perform or generalize to new data\n",
    "- stratified cross-validation techniques are quite common as well when dataset is scarce (small)\n",
    "    - e.g. 10-fold cross-validation is a common practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and selecting a predictive model\n",
    "\n",
    "- each classifier or ML algorithm may have its inherent biases on different type of problem and dataset\n",
    "- in practice, it's essential to comapre at least a handful of different algorithms in order to train and select the best performing model\n",
    "- typically certain pre-defined metrics are used to compare performance\n",
    "    - e.g. accuracy (proportion of correctly classified instances) and many others (covered later...)\n",
    "- default parameters used by algorithms may work well but not guaranteed\n",
    "- these hyperparameters may need to be fine-tuned for optimal performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating models and predicting unseen data instances\n",
    "- the best model, that has been fitted on the training set, is evaluated against the unseen data to estimate generalization error\n",
    "- if satisfied with the model's performance, it's then deployed and applied to the new, unknown dataset in the real-word\n",
    "- same scaling techniques (normalization) and dimensionality reduction technique and the parameters are latter reapplied to transform the new data instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Python for machine learning\n",
    "\n",
    "- active developers and open source community producing a large number of useful libraries\n",
    "- NumPy, SciPy on lower-layer uses Fortran and C implementations for fast vector operations on multidimensional arrays\n",
    "- scikit-learn library has all the popular open-soruce machine learning algorithms\n",
    "- several deep learning frameworks (TensorFlow, Fast.ai, PyTorch) have Python extensions or built with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
